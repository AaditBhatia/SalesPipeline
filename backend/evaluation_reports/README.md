# Evaluation Reports\n\nThis directory stores JSON evaluation reports generated by the model evaluation framework.\n\nReports are automatically created when running evaluations via:\n- API: POST /api/leads/evaluation/run\n- Script: python scripts/run_evaluation.py --all\n\nEach report is saved with timestamp: eval_report_YYYYMMDD_HHMMSS.json
